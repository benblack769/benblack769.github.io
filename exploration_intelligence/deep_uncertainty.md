---
title: "Deep uncertainty"
slug: deep-uncertainty
under_construction: true
excerpt: "An essay on the problems of unparameterizable uncertainty in society and the solutions we come to as individuals."
comments: false
share: false
---

What can a water molecule tell of its fate? It can look to the left, and see another molecule about to collide with it. It can look to the right, and tell that there is nothing there, suggesting it will be pushed in that direction soon. It can tell if it is closely packed with and connected to other molecules in a liquid or bouncing around loosely in a gas.

If this is an observant and well informed molecule, perhaps it can even look at neighboring water droplets in the cloud, and see that their density and size is increasing, suggesting it is about to fall to the ground as rain. But after it falls to the ground, where will it end up? Will it end up mixing will salt in the ocean? Being absorbed by a tree on land? Or something else entirely, something out of the realm of experience and knowledge of this molecule and all its neighbors?

This last case is deep uncertainty, this uncertainty that defies all attempts at estimation and probability. That dives off not only the long tail of the distribution, but out of the dimensional scale of a multidimensional analysis entirely.

Now, for a student of probability, this idea seems lazy and unnatural. Everything fits on the dimensional scale by definition. Anything independent of the variables is treated as error or noise, and is treated formally in the analysis. But what sorts of assumptions are required to treat it formally? These assumptions are the form deep uncertainty takes in mathematical treatments of uncertainty.

Take *p* values, the central statistical tool in the social sciences. *p* values suggest how probable a known variable correlates with the outcome, given that there are unknowns creating noise in the outcome. This is incredibly powerful tool for knowledge because it allows us to determine correlations in the world. The problem? It assumes that the noise is normally distributed. If the noise has a long tail, then the estimated variance can be  much lower than the actual variance, creating much better *p* values than should actually occur.



 After all, these things are independent from the data, i.e. you don't have any way of studying them, so why bother? Well the reason you bother is that these uncertainties are often far more important to your future success than the thing you are studying.
