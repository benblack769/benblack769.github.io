
<h3 id="personal-project">Personal project</h3>

<ul>
  <li><a href="https://github.com/benblack769/reward-surfaces/">Repo</a></li>
  <li><a href="https://benblack769.github.io/posts/projects/reward-surfaces/">Preliminary experiments writeup</a></li>
</ul>

<h3 id="list-of-relevant-papers">List of relevant papers</h3>

<ul>
  <li>Training Larger Networks for Deep Reinforcement Learning: https://arxiv.org/pdf/2102.07920.pdf</li>
  <li>Visualizing the Loss Landscape of Neural Nets https://arxiv.org/pdf/1712.09913.pdf</li>
  <li>http://lukemetz.com/exploring-hyperparameter-meta-loss-landscapes-with-jax/</li>
  <li>ANALYZING REINFORCEMENT LEARNING BENCHMARKS WITH RANDOM WEIGHT GUESSING https://arxiv.org/pdf/2004.07707.pdf</li>
  <li>Exploring Model-based Planning with Policy Networks https://arxiv.org/pdf/1906.08649.pdf</li>
  <li>Understanding the Impact of Entropy on Policy Optimization https://arxiv.org/pdf/1811.11214.pdf</li>
  <li>Fantastic Generalization Measures and Where to Find Them: https://arxiv.org/pdf/1912.02178.pdf â€” worst case sharpness (similar to volume) best predictor is sharpness relative to parameter magnitude</li>
  <li>Implementation matters in deep policy gradients https://arxiv.org/pdf/2005.12729.pdf</li>
  <li>A closer look at deep policy gradients https://arxiv.org/abs/1811.02553
    <ul>
      <li>https://www.reddit.com/r/MachineLearning/comments/9v0r0c/r_are_deep_policy_gradient_algorithms_truly/</li>
    </ul>
  </li>
</ul>
